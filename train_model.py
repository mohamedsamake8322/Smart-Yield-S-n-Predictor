import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import numpy as np
import logging
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# âœ… DÃ©finition du pÃ©riphÃ©rique (CPU uniquement)
device = torch.device("cpu")

# âœ… Configuration du logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# ðŸ“‚ VÃ©rification et crÃ©ation du dossier "model"
MODEL_DIR = "model"
os.makedirs(MODEL_DIR, exist_ok=True)
logging.info(f"âœ… Directory verified: {MODEL_DIR}")

# ðŸ“¥ DÃ©tection automatique des colonnes du dataset
def detect_input_size(csv_path="data.csv"):
    """DÃ©tecte automatiquement le nombre de colonnes de features du CSV."""
    df = pd.read_csv(csv_path)
    logging.info(f"ðŸ”Ž Colonnes disponibles dans le dataset : {df.columns.tolist()}")

    if "yield" not in df.columns:
        raise KeyError("ðŸ›‘ Erreur : La colonne 'yield' n'existe pas dans le dataset. VÃ©rifie ton fichier CSV.")

    input_size = len(df.columns) - 1  # ðŸš€ Ignorer la colonne cible (ex: 'yield')
    logging.info(f"âœ… DÃ©tection des features : {input_size} colonnes utilisÃ©es pour l'entraÃ®nement.")
    return input_size, df

# ðŸ“¥ Chargement et prÃ©traitement des donnÃ©es
def load_data(df):
    logging.info("ðŸ”„ PrÃ©traitement du dataset...")
    
    # âœ… Nettoyage des donnÃ©es
    df = df.apply(pd.to_numeric, errors="coerce")  # ðŸ”¥ Convertir toutes les valeurs en numÃ©riques
    df.fillna(0, inplace=True)  # âœ… Remplacer les NaN par 0

    # âœ… SÃ©paration des features et de la cible
    X = df.drop(columns=["yield"])
    y = df["yield"]

    return train_test_split(X, y, test_size=0.2, random_state=42)

# ðŸ“Œ DÃ©tection du input_size et chargement des donnÃ©es
try:
    input_size, df = detect_input_size()
    X_train, X_test, y_train, y_test = load_data(df)
except KeyError as e:
    logging.error(str(e))
    exit(1)

# ðŸ”¥ DÃ©finition du modÃ¨le PyTorch
class PyTorchModel(nn.Module):
    def __init__(self, input_size):
        super(PyTorchModel, self).__init__()

        # âœ… AdaptabilitÃ© automatique au nombre d'entrÃ©es
        self.fc1 = nn.Linear(input_size, 64).to(device)
        self.fc2 = nn.Linear(64, 32).to(device)
        self.fc3 = nn.Linear(32, 1).to(device)

    def forward(self, x):
        x = x.to(device)  # âœ… Envoi des donnÃ©es vers CPU
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# ðŸ“Œ Instanciation du modÃ¨le
model = PyTorchModel(input_size)

# ðŸ”§ DÃ©finition de la fonction de coÃ»t et de l'optimiseur
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# âœ… Conversion des donnÃ©es en tensors avec passage sur CPU
X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)

# ðŸš€ EntraÃ®nement du modÃ¨le PyTorch
for epoch in range(500):
    optimizer.zero_grad()
    predictions = model(X_train_tensor)
    loss = criterion(predictions, y_train_tensor)
    loss.backward()
    optimizer.step()

    if epoch % 50 == 0:
        logging.info(f"Epoch {epoch}, Loss: {loss.item():.4f}")

# ðŸ“Š Ã‰valuation du modÃ¨le
X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)

with torch.no_grad():
    predictions = model(X_test_tensor)
    rmse = mean_squared_error(y_test_tensor.numpy(), predictions.numpy(), squared=False)
    r2 = r2_score(y_test_tensor.numpy(), predictions.numpy())

metrics = {
    "rmse": float(rmse),
    "r2": float(r2)
}

# ðŸ’¾ Sauvegarde du modÃ¨le
MODEL_PATH = os.path.join(MODEL_DIR, "disease_model.pth")
torch.save(model.state_dict(), MODEL_PATH)  # âœ… Sauvegarde correcte
logging.info(f"âœ… Model saved successfully in {MODEL_PATH}")

# ðŸ“Š Sauvegarde des mÃ©triques
METRICS_PATH = os.path.join(MODEL_DIR, "retrained_model_metrics.json")
with open(METRICS_PATH, "w") as f:
    json.dump(metrics, f)
logging.info(f"ðŸ“Š Metrics logged in {METRICS_PATH}")

# ðŸš€ Fin de l'entraÃ®nement
logging.info("ðŸŽ¯ âœ… ModÃ¨le entraÃ®nÃ© et prÃªt Ã  Ãªtre utilisÃ© !")
